{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "37d4b555",
      "metadata": {
        "id": "37d4b555"
      },
      "source": [
        "# Deep Learning (TensorFlow, Keras) with ResNet50: Image Binary Classifier (Part 2)\n",
        "In this project, a model is trained to perform binary classifiaction for cats and dogs pictures. The pretrained model ResNet50 is used. This document is the second part of the whole training process."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5720a640",
      "metadata": {},
      "source": [
        "## Iteration 2: Model retraining with data augmentation, fine-tuning (last 10 layers only) and learning_rate = 1e-5 (smaller)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fPgTDtJJyM24",
      "metadata": {
        "id": "fPgTDtJJyM24"
      },
      "outputs": [],
      "source": [
        "# (height, width, channels)\n",
        "input_shape = (224, 224, 3)\n",
        "batch_size = 8\n",
        "learning_rate = 1e-5\n",
        "neurons = 128\n",
        "path_dataset = '../dataset_cat_dogs'\n",
        "folder_cat = 'Cat'\n",
        "folder_dog = 'Dog'\n",
        "folder_models = '../models'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "25443748",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "25443748",
        "outputId": "582675ae-9e70-4b92-8284-28cc33598c44"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "from tensorflow.keras.models import load_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "09197178",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "09197178",
        "outputId": "170de5ea-d5a0-4ca6-cdf4-06a9a48d07e9"
      },
      "outputs": [],
      "source": [
        "# Find how many cats and dogs images exist\n",
        "cat_imgs = os.listdir(os.path.join(path_dataset,folder_cat))\n",
        "dog_imgs = os.listdir(os.path.join(path_dataset,folder_dog))\n",
        "print(f'Cat images found: {len(cat_imgs)}')\n",
        "print(f'Dog images found: {len(dog_imgs)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e82e440b",
      "metadata": {},
      "source": [
        "Classes are balanced."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "96948d32",
      "metadata": {},
      "source": [
        "### Data augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f7fa1120",
      "metadata": {
        "id": "f7fa1120"
      },
      "outputs": [],
      "source": [
        "def load_data(path, input_shape=input_shape, batch_size=batch_size, seed=123, validation_split=0.2):\n",
        "    \"\"\"Function to create 2 ImageDataGenerators to split dataset into train and validation datasets.\n",
        "    Data augmentation is not implemented for the validation dataset.\"\"\"\n",
        "    height, width = input_shape[:2]\n",
        "    datagen = ImageDataGenerator(rescale=1.0/255, zoom_range=0.15,\n",
        "        horizontal_flip=True, vertical_flip=False,\n",
        "        height_shift_range=0.15, width_shift_range=0.15,\n",
        "        brightness_range=(0.8, 1.2), rotation_range=20,\n",
        "        validation_split=validation_split\n",
        "    )\n",
        "    train_data = datagen.flow_from_directory(path,\n",
        "        target_size=(height, width), batch_size=batch_size,\n",
        "        class_mode='binary', subset='training', seed=seed\n",
        "    )\n",
        "    val_datagen = ImageDataGenerator(rescale=1.0/255,\n",
        "        validation_split=validation_split\n",
        "    )\n",
        "    val_data = val_datagen.flow_from_directory(path,\n",
        "        target_size=(height, width), batch_size=batch_size,\n",
        "        class_mode='binary', subset='validation', seed=seed\n",
        "    )\n",
        "    return train_data, val_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8edoXkf1yFm2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8edoXkf1yFm2",
        "outputId": "1fbf590d-4c1a-45c8-bd4a-058478bba0d5"
      },
      "outputs": [],
      "source": [
        "# Split training and validation datasets\n",
        "train, val = load_data(path_dataset)\n",
        "\n",
        "print(f\"Classes found: {train.class_indices}\")\n",
        "print(f\"Training images: {train.samples}\")\n",
        "print(f\"Validation images: {val.samples}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "adab49d2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 506
        },
        "id": "adab49d2",
        "outputId": "1680a9bc-f757-46c3-e5b3-d006dc8b31ba"
      },
      "outputs": [],
      "source": [
        "# Obtain images and target\n",
        "images, labels = next(train)\n",
        "\n",
        "# Show 8 training images (batch_size=8)\n",
        "figure, axes = plt.subplots(nrows=2,ncols=4, figsize=(8, 6))\n",
        "for item in zip(axes.ravel(), images, labels):\n",
        "    axes, image, target = item\n",
        "    axes.imshow(image)\n",
        "    axes.set_title(f'Target: {target:.0f}')\n",
        "    axes.set_xticks([])\n",
        "    axes.set_yticks([])\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Image dimensions\n",
        "print(images.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e6292316",
      "metadata": {},
      "source": [
        "### Model retraining (iteration 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "nAHEnmOqyFm5",
      "metadata": {
        "id": "nAHEnmOqyFm5"
      },
      "outputs": [],
      "source": [
        "def train_model(model, train_data, val_data, epochs, version_model, folder_models=folder_models):\n",
        "    \"\"\"Function to train the model and save the best one\n",
        "    according to the validation accuracy.\"\"\"\n",
        "    file_name = os.path.join(folder_models,f'binary_model_v{version_model}.h5')\n",
        "    callbacks = [\n",
        "        EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True, verbose=0),\n",
        "        ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-6, verbose=0),\n",
        "        ModelCheckpoint(file_name, monitor='val_accuracy', save_best_only=True, verbose=1)\n",
        "    ]\n",
        "\n",
        "    history = model.fit(train_data, validation_data=val_data,\n",
        "              epochs=epochs, callbacks=callbacks, verbose=2)\n",
        "\n",
        "    return model, history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "21dbcfca",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load model v1\n",
        "model_v2 = load_model(os.path.join(folder_models,'binary_model_v1.h5'))\n",
        "model_v2.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ad1d77a",
      "metadata": {},
      "outputs": [],
      "source": [
        "epochs = 20\n",
        "version_model = 2\n",
        "print(f\"Parameters: batch_size = {batch_size}, learning_rate = {learning_rate}, neurons = {neurons}, epochs = {epochs}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "94852f1b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "94852f1b",
        "outputId": "8d916d06-3834-41b5-8c98-6f94a0bd0ac4"
      },
      "outputs": [],
      "source": [
        "# last 10 layers\n",
        "for layer in model_v2.layers[0].layers[-10:]:\n",
        "    layer.trainable = True\n",
        "\n",
        "# Recompile\n",
        "model_v2.compile(optimizer=Adam(learning_rate=learning_rate),\n",
        "                 loss='binary_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "68d45008",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(f\"TensorFlow Version: {tf.__version__}\")\n",
        "\n",
        "# Ensure GPU is available\n",
        "physical_devices = tf.config.list_physical_devices('GPU')\n",
        "if len(physical_devices) > 0:\n",
        "    tf.config.experimental.set_memory_growth(physical_devices[0],True)\n",
        "    print(\"GPU is available and memory growth is enabled.\")\n",
        "else:\n",
        "    print(\"GPU not available, training will be on CPU.\")\n",
        "    \n",
        "# Retrain the model\n",
        "model_v2, history_stage2 = train_model(model_v2, train, val, epochs=epochs, version_model=version_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "446c178c",
      "metadata": {
        "id": "446c178c"
      },
      "source": [
        "**Result 2:** val_accuracy=?%."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a5281c28",
      "metadata": {},
      "outputs": [],
      "source": [
        "pd.DataFrame(history_stage2.history).plot(figsize=(12, 4))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b2a96191",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save model\n",
        "# model.save(os.path.join(folder_models,f'binary_model_v{version_model}.keras'))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5d67d9e8",
      "metadata": {},
      "source": [
        "In the next iteration, the model will be retrained, data augmentation and fine-tuning (the last 20 layers) will be performed."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "env (3.8.10)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
