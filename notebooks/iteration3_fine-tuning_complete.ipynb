{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "37d4b555",
      "metadata": {
        "id": "37d4b555"
      },
      "source": [
        "# Deep Learning (TensorFlow, Keras) with ResNet50: Image Binary Classifier (Part 3)\n",
        "In this project, a model is trained to perform binary classifiaction for cats and dogs pictures. The pretrained model ResNet50 is used. This document is the third part of the whole training process."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e0566921",
      "metadata": {},
      "source": [
        "## Iteration 3: Model retraining with data augmentation, fine-tuning (last 20 layers) and learning_rate = 1e-5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "fPgTDtJJyM24",
      "metadata": {
        "id": "fPgTDtJJyM24"
      },
      "outputs": [],
      "source": [
        "# (height, width, channels)\n",
        "input_shape = (224, 224, 3)\n",
        "batch_size = 8\n",
        "learning_rate = 1e-5\n",
        "neurons = 128\n",
        "path_dataset = '../dataset_cat_dogs'\n",
        "folder_cat = 'Cat'\n",
        "folder_dog = 'Dog'\n",
        "folder_models = '../models'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "25443748",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "25443748",
        "outputId": "582675ae-9e70-4b92-8284-28cc33598c44"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-09-29 15:45:17.278411: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2025-09-29 15:45:17.756154: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2025-09-29 15:45:17.768662: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2025-09-29 15:45:25.353670: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "from tensorflow.keras.models import load_model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "96948d32",
      "metadata": {},
      "source": [
        "### Data augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "f7fa1120",
      "metadata": {
        "id": "f7fa1120"
      },
      "outputs": [],
      "source": [
        "def load_data(path, input_shape=input_shape, batch_size=batch_size, seed=123, validation_split=0.2):\n",
        "    \"\"\"Function to create 2 ImageDataGenerators to split dataset into train and validation datasets.\n",
        "    Data augmentation is not implemented for the validation dataset.\"\"\"\n",
        "    height, width = input_shape[:2]\n",
        "    datagen = ImageDataGenerator(rescale=1.0/255, zoom_range=0.15,\n",
        "        horizontal_flip=True, vertical_flip=False,\n",
        "        height_shift_range=0.15, width_shift_range=0.15,\n",
        "        brightness_range=(0.8, 1.2), rotation_range=20,\n",
        "        validation_split=validation_split\n",
        "    )\n",
        "    train_data = datagen.flow_from_directory(path,\n",
        "        target_size=(height, width), batch_size=batch_size,\n",
        "        class_mode='binary', subset='training', seed=seed\n",
        "    )\n",
        "    val_datagen = ImageDataGenerator(rescale=1.0/255,\n",
        "        validation_split=validation_split\n",
        "    )\n",
        "    val_data = val_datagen.flow_from_directory(path,\n",
        "        target_size=(height, width), batch_size=batch_size,\n",
        "        class_mode='binary', subset='validation', seed=seed\n",
        "    )\n",
        "    return train_data, val_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "8edoXkf1yFm2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8edoXkf1yFm2",
        "outputId": "1fbf590d-4c1a-45c8-bd4a-058478bba0d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 19968 images belonging to 2 classes.\n",
            "Found 4991 images belonging to 2 classes.\n",
            "Classes found: {'Cat': 0, 'Dog': 1}\n",
            "Training images: 19968\n",
            "Validation images: 4991\n"
          ]
        }
      ],
      "source": [
        "# Split training and validation datasets\n",
        "train, val = load_data(path_dataset)\n",
        "\n",
        "print(f\"Classes found: {train.class_indices}\")\n",
        "print(f\"Training images: {train.samples}\")\n",
        "print(f\"Validation images: {val.samples}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "85650614",
      "metadata": {},
      "source": [
        "### Model retraining (iteration 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "nAHEnmOqyFm5",
      "metadata": {
        "id": "nAHEnmOqyFm5"
      },
      "outputs": [],
      "source": [
        "def train_model(model, train_data, val_data, epochs, version_model, folder_models=folder_models):\n",
        "    file_name = os.path.join(folder_models,f'binary_model_v{version_model}.h5')\n",
        "    callbacks = [\n",
        "        EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True, verbose=0),\n",
        "        ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-6, verbose=0),\n",
        "        ModelCheckpoint(file_name, monitor='val_accuracy', save_best_only=True, verbose=1)\n",
        "    ]\n",
        "\n",
        "    history = model.fit(train_data, validation_data=val_data,\n",
        "              epochs=epochs, callbacks=callbacks, verbose=2)\n",
        "\n",
        "    return model, history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "21dbcfca",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " resnet50 (Functional)       (None, 7, 7, 2048)        23587712  \n",
            "                                                                 \n",
            " global_average_pooling2d (  (None, 2048)              0         \n",
            " GlobalAveragePooling2D)                                         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               262272    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 23850113 (90.98 MB)\n",
            "Trainable params: 9193729 (35.07 MB)\n",
            "Non-trainable params: 14656384 (55.91 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Load model v2\n",
        "model_v3 = load_model(os.path.join(folder_models,'binary_model_v2.h5'))\n",
        "model_v3.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "8ad1d77a",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parameters: batch_size = 8, learning_rate = 1e-05, neurons = 128, epochs = 20\n"
          ]
        }
      ],
      "source": [
        "epochs = 20\n",
        "version_model = 3\n",
        "print(f\"Parameters: batch_size = {batch_size}, learning_rate = {learning_rate}, neurons = {neurons}, epochs = {epochs}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "94852f1b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "94852f1b",
        "outputId": "8d916d06-3834-41b5-8c98-6f94a0bd0ac4"
      },
      "outputs": [],
      "source": [
        "# last 20 layers\n",
        "for layer in model_v3.layers[0].layers[-20:]:\n",
        "    layer.trainable = True\n",
        "\n",
        "# Recompile\n",
        "model_v3.compile(optimizer=Adam(learning_rate=learning_rate),\n",
        "                 loss='binary_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "68d45008",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TensorFlow Version: 2.13.1\n",
            "GPU not available, training will be on CPU.\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-09-29 15:46:37.143909: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 25690112 exceeds 10% of free system memory.\n",
            "2025-09-29 15:46:37.872791: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 25690112 exceeds 10% of free system memory.\n",
            "2025-09-29 15:46:38.004372: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 26615808 exceeds 10% of free system memory.\n",
            "2025-09-29 15:46:38.020688: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 25690112 exceeds 10% of free system memory.\n",
            "2025-09-29 15:46:38.031538: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 25690112 exceeds 10% of free system memory.\n",
            "/home/ant/TensorFlow-Keras-ResNet50-HuggingFace/env/lib/python3.8/site-packages/PIL/TiffImagePlugin.py:900: UserWarning: Truncated File Read\n",
            "  warnings.warn(str(msg))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 1: val_accuracy improved from -inf to 0.78622, saving model to ../models/binary_model_v3.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/ant/TensorFlow-Keras-ResNet50-HuggingFace/env/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2496/2496 - 4370s - loss: 0.5271 - accuracy: 0.7321 - val_loss: 0.4475 - val_accuracy: 0.7862 - lr: 1.0000e-05 - 4370s/epoch - 2s/step\n",
            "Epoch 2/20\n",
            "\n",
            "Epoch 2: val_accuracy improved from 0.78622 to 0.78742, saving model to ../models/binary_model_v3.h5\n",
            "2496/2496 - 3786s - loss: 0.5264 - accuracy: 0.7339 - val_loss: 0.4528 - val_accuracy: 0.7874 - lr: 1.0000e-05 - 3786s/epoch - 2s/step\n",
            "Epoch 3/20\n",
            "\n",
            "Epoch 3: val_accuracy did not improve from 0.78742\n",
            "2496/2496 - 2353s - loss: 0.5212 - accuracy: 0.7401 - val_loss: 0.4484 - val_accuracy: 0.7812 - lr: 1.0000e-05 - 2353s/epoch - 943ms/step\n",
            "Epoch 4/20\n",
            "\n",
            "Epoch 4: val_accuracy improved from 0.78742 to 0.79603, saving model to ../models/binary_model_v3.h5\n",
            "2496/2496 - 2674s - loss: 0.5168 - accuracy: 0.7395 - val_loss: 0.4421 - val_accuracy: 0.7960 - lr: 1.0000e-05 - 2674s/epoch - 1s/step\n",
            "Epoch 5/20\n",
            "\n",
            "Epoch 5: val_accuracy did not improve from 0.79603\n",
            "2496/2496 - 4020s - loss: 0.5126 - accuracy: 0.7423 - val_loss: 0.4454 - val_accuracy: 0.7918 - lr: 1.0000e-05 - 4020s/epoch - 2s/step\n",
            "Epoch 6/20\n",
            "\n",
            "Epoch 6: val_accuracy did not improve from 0.79603\n",
            "2496/2496 - 4231s - loss: 0.5125 - accuracy: 0.7456 - val_loss: 0.4539 - val_accuracy: 0.7828 - lr: 1.0000e-05 - 4231s/epoch - 2s/step\n",
            "Epoch 7/20\n"
          ]
        }
      ],
      "source": [
        "print(f\"TensorFlow Version: {tf.__version__}\")\n",
        "\n",
        "# Ensure GPU is available\n",
        "physical_devices = tf.config.list_physical_devices('GPU')\n",
        "if len(physical_devices) > 0:\n",
        "    tf.config.experimental.set_memory_growth(physical_devices[0],True)\n",
        "    print(\"GPU is available and memory growth is enabled.\")\n",
        "else:\n",
        "    print(\"GPU not available, training will be on CPU.\")\n",
        "    \n",
        "# Retrain the model\n",
        "model_v3, history_stage3 = train_model(model_v3, train, val, epochs=epochs, version_model=version_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "446c178c",
      "metadata": {
        "id": "446c178c"
      },
      "source": [
        "**Result 3:** val_accuracy=?%."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a5281c28",
      "metadata": {},
      "outputs": [],
      "source": [
        "pd.DataFrame(history_stage3.history).plot(figsize=(12, 4))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b2a96191",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save model\n",
        "# model.save(os.path.join(folder_models,f'binary_model_v{version_model}.keras'))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5d67d9e8",
      "metadata": {},
      "source": [
        "Finally, the accuracy model is 85%."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "env (3.8.10)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
