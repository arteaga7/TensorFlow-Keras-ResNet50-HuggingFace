{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "37d4b555",
      "metadata": {
        "id": "37d4b555"
      },
      "source": [
        "# Deep Learning (TensorFlow, Keras) with ResNet50: Image Binary Classifier (Part 1)\n",
        "In this project, a model is trained to perform binary classifiaction for cats and dogs pictures. The pretrained model ResNet50 is used. This document is the first part of the whole training process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fPgTDtJJyM24",
      "metadata": {
        "id": "fPgTDtJJyM24"
      },
      "outputs": [],
      "source": [
        "# (height, width, channels)\n",
        "input_shape = (224, 224, 3)\n",
        "batch_size = 8\n",
        "learning_rate = 1e-4\n",
        "neurons = 128\n",
        "path_dataset = '../dataset_cat_dogs'\n",
        "folder_cat = 'Cat'\n",
        "folder_dog = 'Dog'\n",
        "folder_models = '../models'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c7445490",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Path in Google Colab\n",
        "# path_dataset = '/content/drive/MyDrive/Colab Notebooks/dataset_cat_dogs'\n",
        "\n",
        "# Mount Google Drive if using Google Colab\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "25443748",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "25443748",
        "outputId": "582675ae-9e70-4b92-8284-28cc33598c44"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "09197178",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "09197178",
        "outputId": "170de5ea-d5a0-4ca6-cdf4-06a9a48d07e9"
      },
      "outputs": [],
      "source": [
        "# Find how many cats and dogs images exist\n",
        "cat_imgs = os.listdir(os.path.join(path_dataset,folder_cat))\n",
        "dog_imgs = os.listdir(os.path.join(path_dataset,folder_dog))\n",
        "print(f'Cat images found: {len(cat_imgs)}')\n",
        "print(f'Dog images found: {len(dog_imgs)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e82e440b",
      "metadata": {},
      "source": [
        "Classes are balanced."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "96948d32",
      "metadata": {},
      "source": [
        "## No Data augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f7fa1120",
      "metadata": {
        "id": "f7fa1120"
      },
      "outputs": [],
      "source": [
        "def load_data(path, input_shape=input_shape, batch_size=batch_size, seed=123, validation_split=0.2):\n",
        "    \"\"\"Function to create 2 ImageDataGenerators to split dataset into train and validation datasets.\n",
        "    Data augmentation is not implemented for the validation dataset.\"\"\"\n",
        "    height, width = input_shape[:2]\n",
        "    datagen = ImageDataGenerator(rescale=1.0/255, zoom_range=0,\n",
        "        horizontal_flip=True, vertical_flip=False,\n",
        "        height_shift_range=0, width_shift_range=0,\n",
        "        brightness_range=(0.99, 1.0), rotation_range=0,\n",
        "        validation_split=validation_split\n",
        "    )\n",
        "    train_data = datagen.flow_from_directory(path,\n",
        "        target_size=(height, width), batch_size=batch_size,\n",
        "        class_mode='binary', subset='training', seed=seed\n",
        "    )\n",
        "    val_datagen = ImageDataGenerator(rescale=1.0/255,\n",
        "        validation_split=validation_split\n",
        "    )\n",
        "    val_data = val_datagen.flow_from_directory(path,\n",
        "        target_size=(height, width), batch_size=batch_size,\n",
        "        class_mode='binary', subset='validation', seed=seed\n",
        "    )\n",
        "    return train_data, val_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8edoXkf1yFm2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8edoXkf1yFm2",
        "outputId": "1fbf590d-4c1a-45c8-bd4a-058478bba0d5"
      },
      "outputs": [],
      "source": [
        "# Split training and validation datasets\n",
        "train, val = load_data(path_dataset)\n",
        "\n",
        "print(f\"Classes found: {train.class_indices}\")\n",
        "print(f\"Training images: {train.samples}\")\n",
        "print(f\"Validation images: {val.samples}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "adab49d2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 506
        },
        "id": "adab49d2",
        "outputId": "1680a9bc-f757-46c3-e5b3-d006dc8b31ba"
      },
      "outputs": [],
      "source": [
        "# Obtain images and target\n",
        "images, labels = next(train)\n",
        "\n",
        "# Show 8 training images (batch_size=8)\n",
        "figure, axes = plt.subplots(nrows=2,ncols=4, figsize=(8, 6))\n",
        "for item in zip(axes.ravel(), images, labels):\n",
        "    axes, image, target = item\n",
        "    axes.imshow(image)\n",
        "    axes.set_title(f'Target: {target:.0f}')\n",
        "    axes.set_xticks([])\n",
        "    axes.set_yticks([])\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Image dimensions\n",
        "print(images.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6e9a8ce9",
      "metadata": {
        "id": "6e9a8ce9"
      },
      "source": [
        "## Iteration 1: Model creation and training without data augmentation (no fine-tuning yet)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "nAHEnmOqyFm5",
      "metadata": {
        "id": "nAHEnmOqyFm5"
      },
      "outputs": [],
      "source": [
        "def create_resnet_model(input_shape=input_shape, neurons=neurons,\n",
        "                        learning_rate=learning_rate):\n",
        "    \"\"\"Function to create the model using the pretrained model\n",
        "    'ResNet50' and adding some final layers. The backbone is 'ResNet50',\n",
        "    but it is freezed (not trained) in this iteration.\"\"\"\n",
        "    \n",
        "    backbone = ResNet50(weights='imagenet', input_shape=input_shape,\n",
        "                        include_top=False)\n",
        "\n",
        "    # Freeze ResNet50 without the top\n",
        "    backbone.trainable = False\n",
        "    model = Sequential()\n",
        "    model.add(backbone)\n",
        "    model.add(GlobalAveragePooling2D())\n",
        "    model.add(Dense(neurons, activation='relu'))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    optimizer = Adam(learning_rate=learning_rate)\n",
        "    model.compile(optimizer=optimizer,\n",
        "                  loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def train_model(model, train_data, val_data, epochs, version_model):\n",
        "    \"\"\"Function to train the model and save the best one\n",
        "    according to the validation accuracy.\"\"\"\n",
        "    file_name = os.path.join(folder_models,f'binary_model_v{version_model}.h5')\n",
        "    \n",
        "    callbacks = [\n",
        "        EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True, verbose=0),\n",
        "        ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-6, verbose=0),\n",
        "        ModelCheckpoint(file_name, monitor='val_accuracy', save_best_only=True, verbose=1)\n",
        "    ]\n",
        "\n",
        "    history = model.fit(train_data, validation_data=val_data,\n",
        "              epochs=epochs, callbacks=callbacks, verbose=2)\n",
        "\n",
        "    return model, history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ad1d77a",
      "metadata": {},
      "outputs": [],
      "source": [
        "epochs = 20\n",
        "version_model = 1\n",
        "print(f\"Parameters: batch_size = {batch_size}, learning_rate = {learning_rate}, neurons = {neurons}, epochs = {epochs}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "94852f1b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "94852f1b",
        "outputId": "8d916d06-3834-41b5-8c98-6f94a0bd0ac4"
      },
      "outputs": [],
      "source": [
        "# Create and train the model v1\n",
        "model = create_resnet_model()\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "68d45008",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(f\"TensorFlow Version: {tf.__version__}\")\n",
        "\n",
        "# Ensure GPU is available\n",
        "physical_devices = tf.config.list_physical_devices('GPU')\n",
        "if len(physical_devices) > 0:\n",
        "    tf.config.experimental.set_memory_growth(physical_devices[0],True)\n",
        "    print(\"GPU is available and memory growth is enabled.\")\n",
        "else:\n",
        "    print(\"GPU not available, training will be on CPU.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6fef21f9",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train the model\n",
        "model, history_stage1 = train_model(model, train, val, epochs=epochs, version_model=version_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "446c178c",
      "metadata": {
        "id": "446c178c"
      },
      "source": [
        "**Result 1:** val_accuracy=?%."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a5281c28",
      "metadata": {},
      "outputs": [],
      "source": [
        "pd.DataFrame(history_stage1.history).plot(figsize=(12, 4))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b2a96191",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save model\n",
        "# model.save(os.path.join(folder_models,f'binary_model_v{version_model}.keras'))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5d67d9e8",
      "metadata": {},
      "source": [
        "In the next iteration, the model will be retrained, data augmentation and fine-tuning will be performed."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "env (3.8.10)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
